
% Default to the notebook output style

    


% Inherit from the specified cell style.




    
\documentclass{article}

    
    
    \usepackage{graphicx} % Used to insert images
    \usepackage{adjustbox} % Used to constrain images to a maximum size 
    \usepackage{color} % Allow colors to be defined
    \usepackage{enumerate} % Needed for markdown enumerations to work
    \usepackage{geometry} % Used to adjust the document margins
    \usepackage{amsmath} % Equations
    \usepackage{amssymb} % Equations
    \usepackage{eurosym} % defines \euro
    \usepackage[mathletters]{ucs} % Extended unicode (utf-8) support
    \usepackage[utf8x]{inputenc} % Allow utf-8 characters in the tex document
    \usepackage{fancyvrb} % verbatim replacement that allows latex
    \usepackage{grffile} % extends the file name processing of package graphics 
                         % to support a larger range 
    % The hyperref package gives us a pdf with properly built
    % internal navigation ('pdf bookmarks' for the table of contents,
    % internal cross-reference links, web links for URLs, etc.)
    \usepackage{hyperref}
    \usepackage{longtable} % longtable support required by pandoc >1.10
    \usepackage{booktabs}  % table support for pandoc > 1.12.2
    

    
    
    \definecolor{orange}{cmyk}{0,0.4,0.8,0.2}
    \definecolor{darkorange}{rgb}{.71,0.21,0.01}
    \definecolor{darkgreen}{rgb}{.12,.54,.11}
    \definecolor{myteal}{rgb}{.26, .44, .56}
    \definecolor{gray}{gray}{0.45}
    \definecolor{lightgray}{gray}{.95}
    \definecolor{mediumgray}{gray}{.8}
    \definecolor{inputbackground}{rgb}{.95, .95, .85}
    \definecolor{outputbackground}{rgb}{.95, .95, .95}
    \definecolor{traceback}{rgb}{1, .95, .95}
    % ansi colors
    \definecolor{red}{rgb}{.6,0,0}
    \definecolor{green}{rgb}{0,.65,0}
    \definecolor{brown}{rgb}{0.6,0.6,0}
    \definecolor{blue}{rgb}{0,.145,.698}
    \definecolor{purple}{rgb}{.698,.145,.698}
    \definecolor{cyan}{rgb}{0,.698,.698}
    \definecolor{lightgray}{gray}{0.5}
    
    % bright ansi colors
    \definecolor{darkgray}{gray}{0.25}
    \definecolor{lightred}{rgb}{1.0,0.39,0.28}
    \definecolor{lightgreen}{rgb}{0.48,0.99,0.0}
    \definecolor{lightblue}{rgb}{0.53,0.81,0.92}
    \definecolor{lightpurple}{rgb}{0.87,0.63,0.87}
    \definecolor{lightcyan}{rgb}{0.5,1.0,0.83}
    
    % commands and environments needed by pandoc snippets
    % extracted from the output of `pandoc -s`
    \providecommand{\tightlist}{%
      \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
    \DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
    % Add ',fontsize=\small' for more characters per line
    \newenvironment{Shaded}{}{}
    \newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.56,0.13,0.00}{{#1}}}
    \newcommand{\DecValTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\FloatTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\CharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\StringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\CommentTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textit{{#1}}}}
    \newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{{#1}}}
    \newcommand{\AlertTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.02,0.16,0.49}{{#1}}}
    \newcommand{\RegionMarkerTok}[1]{{#1}}
    \newcommand{\ErrorTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\NormalTok}[1]{{#1}}
    
    % Define a nice break command that doesn't care if a line doesn't already
    % exist.
    \def\br{\hspace*{\fill} \\* }
    % Math Jax compatability definitions
    \def\gt{>}
    \def\lt{<}
    % Document parameters
    \title{Enron Machine Learning Project}
    
    
    

    % Pygments definitions
    
\makeatletter
\def\PY@reset{\let\PY@it=\relax \let\PY@bf=\relax%
    \let\PY@ul=\relax \let\PY@tc=\relax%
    \let\PY@bc=\relax \let\PY@ff=\relax}
\def\PY@tok#1{\csname PY@tok@#1\endcsname}
\def\PY@toks#1+{\ifx\relax#1\empty\else%
    \PY@tok{#1}\expandafter\PY@toks\fi}
\def\PY@do#1{\PY@bc{\PY@tc{\PY@ul{%
    \PY@it{\PY@bf{\PY@ff{#1}}}}}}}
\def\PY#1#2{\PY@reset\PY@toks#1+\relax+\PY@do{#2}}

\expandafter\def\csname PY@tok@gd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@gu\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}
\expandafter\def\csname PY@tok@gs\endcsname{\let\PY@bf=\textbf}
\expandafter\def\csname PY@tok@gr\endcsname{\def\PY@tc##1{\textcolor[rgb]{1.00,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@cm\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@vg\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@m\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@go\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.53,0.53}{##1}}}
\expandafter\def\csname PY@tok@ge\endcsname{\let\PY@it=\textit}
\expandafter\def\csname PY@tok@vc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@il\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@cs\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.74,0.48,0.00}{##1}}}
\expandafter\def\csname PY@tok@gi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@gh\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@ni\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.60,0.60,0.60}{##1}}}
\expandafter\def\csname PY@tok@nl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@nn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@no\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@na\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.49,0.56,0.16}{##1}}}
\expandafter\def\csname PY@tok@nb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@ne\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.82,0.25,0.23}{##1}}}
\expandafter\def\csname PY@tok@nf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@si\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@s2\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@vi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@nt\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nv\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@s1\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@kd\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@sh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sx\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@bp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@c1\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@kc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@c\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@mf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@err\endcsname{\def\PY@bc##1{\setlength{\fboxsep}{0pt}\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{\strut ##1}}}
\expandafter\def\csname PY@tok@mb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ss\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sr\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@mo\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@kn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@mi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@gp\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@o\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@kr\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@s\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@kp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@w\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\expandafter\def\csname PY@tok@kt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.69,0.00,0.25}{##1}}}
\expandafter\def\csname PY@tok@ow\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@sb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@k\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@se\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.13}{##1}}}
\expandafter\def\csname PY@tok@sd\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}

\def\PYZbs{\char`\\}
\def\PYZus{\char`\_}
\def\PYZob{\char`\{}
\def\PYZcb{\char`\}}
\def\PYZca{\char`\^}
\def\PYZam{\char`\&}
\def\PYZlt{\char`\<}
\def\PYZgt{\char`\>}
\def\PYZsh{\char`\#}
\def\PYZpc{\char`\%}
\def\PYZdl{\char`\$}
\def\PYZhy{\char`\-}
\def\PYZsq{\char`\'}
\def\PYZdq{\char`\"}
\def\PYZti{\char`\~}
% for compatibility with earlier versions
\def\PYZat{@}
\def\PYZlb{[}
\def\PYZrb{]}
\makeatother


    % Exact colors from NB
    \definecolor{incolor}{rgb}{0.0, 0.0, 0.5}
    \definecolor{outcolor}{rgb}{0.545, 0.0, 0.0}



    
    % Prevent overflowing lines due to hard-to-break entities
    \sloppy 
    % Setup hyperref package
    \hypersetup{
      breaklinks=true,  % so long urls are correctly broken across lines
      colorlinks=true,
      urlcolor=blue,
      linkcolor=darkorange,
      citecolor=darkgreen,
      }
    % Slightly bigger margins than the latex defaults
    
    \geometry{verbose,tmargin=1in,bmargin=1in,lmargin=1in,rmargin=1in}
    
    

    \begin{document}
    
    
    \maketitle
    
    

    
    \section{Introduction}\label{introduction}

    Can machine learning be used to Identify Fraud in Enron? Using emails
and financial data released during the Federal investigation, we'll
attempt to identify executives that were persons of interest using
machine learning. A person of interest (POI) is defined as a person who
was indicted for fraud, settled with the government, or testified in
exchange for immunity.

First, a brief background on Enron,before filing for bankruptcy in 2001,
Enron Corporation was one of the largest integrated natural gas and
electricity companies in the world. It marketed natural gas liquids
worldwide and operated one of the largest natural gas transmission
systems in the world, totaling more than 36,000 miles. It was also one
of the largest independent developers and producers of electricity in
the world, serving both industrial and emerging markets. Enron was also
a major supplier of solar and wind renewable energy worldwide, managed
the largest portfolio of natural gas-related risk management contracts
in the world, and was one of the world's biggest independent oil and gas
exploration companies. In North America, Enron was the largest wholesale
marketer of natural gas and electricity. Enron pioneered innovative
trading products, such as gas futures and weather futures, significantly
modernizing the utilities industry. After a surge of growth in the early
1990s, the company ran into difficulties. The magnitude of Enron's
losses was hidden from stockholders. The company folded after a failed
merger deal with Dynegy Inc. in 2001 brought to light massive financial
finagling. The company had ranked number seven on the Fortune 500, and
its failure was the biggest bankruptcy in American history.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}2}]:} \PY{o}{\PYZpc{}}\PY{k}{matplotlib} inline
        \PY{k+kn}{import} \PY{n+nn}{sys}
        \PY{k+kn}{import} \PY{n+nn}{pickle}
        \PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k+kn}{as} \PY{n+nn}{np}
        \PY{k+kn}{import} \PY{n+nn}{matplotlib.pyplot} \PY{k+kn}{as} \PY{n+nn}{plt} 
        \PY{k+kn}{import} \PY{n+nn}{pandas} \PY{k+kn}{as} \PY{n+nn}{pd}
        \PY{n}{pd}\PY{o}{.}\PY{n}{set\PYZus{}option}\PY{p}{(}\PY{l+s}{\PYZsq{}}\PY{l+s}{display.notebook\PYZus{}repr\PYZus{}html}\PY{l+s}{\PYZsq{}}\PY{p}{,} \PY{n+nb+bp}{True}\PY{p}{)}
        
        \PY{k}{def} \PY{n+nf}{\PYZus{}repr\PYZus{}latex\PYZus{}}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{)}\PY{p}{:}
            \PY{k}{return} \PY{l+s}{\PYZdq{}}\PY{l+s}{\PYZbs{}}\PY{l+s}{centering\PYZob{}}\PY{l+s+si}{\PYZpc{}s}\PY{l+s}{\PYZcb{}}\PY{l+s}{\PYZdq{}} \PY{o}{\PYZpc{}} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{to\PYZus{}latex}\PY{p}{(}\PY{p}{)}
        
        \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{o}{.}\PY{n}{\PYZus{}repr\PYZus{}latex\PYZus{}} \PY{o}{=} \PY{n}{\PYZus{}repr\PYZus{}latex\PYZus{}}  \PY{c}{\PYZsh{} monkey patch pandas DataFrame}
        
        
        
        \PY{n}{sys}\PY{o}{.}\PY{n}{path}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{../tools/}\PY{l+s}{\PYZdq{}}\PY{p}{)}
        
        \PY{k+kn}{from} \PY{n+nn}{feature\PYZus{}format} \PY{k+kn}{import} \PY{n}{featureFormat}\PY{p}{,} \PY{n}{targetFeatureSplit}
        \PY{k+kn}{from} \PY{n+nn}{tester} \PY{k+kn}{import} \PY{n}{test\PYZus{}classifier}\PY{p}{,} \PY{n}{dump\PYZus{}classifier\PYZus{}and\PYZus{}data}
        
        \PY{c}{\PYZsh{}\PYZsh{} Determine Best features}
        \PY{k+kn}{from} \PY{n+nn}{sklearn.feature\PYZus{}selection} \PY{k+kn}{import} \PY{n}{SelectKBest}
        \PY{k+kn}{from} \PY{n+nn}{sklearn.feature\PYZus{}selection} \PY{k+kn}{import} \PY{n}{f\PYZus{}classif}\PY{p}{,}\PY{n}{f\PYZus{}regression}
        
        \PY{c}{\PYZsh{}\PYZsh{} Classifiers}
        \PY{k+kn}{from} \PY{n+nn}{sklearn.svm} \PY{k+kn}{import} \PY{n}{LinearSVC}
        \PY{k+kn}{from} \PY{n+nn}{sklearn.naive\PYZus{}bayes} \PY{k+kn}{import} \PY{n}{GaussianNB}
        \PY{k+kn}{from} \PY{n+nn}{sklearn.neighbors} \PY{k+kn}{import} \PY{n}{KNeighborsClassifier}
        \PY{k+kn}{from} \PY{n+nn}{sklearn.tree} \PY{k+kn}{import} \PY{n}{DecisionTreeClassifier}
        \PY{k+kn}{from} \PY{n+nn}{sklearn.cluster} \PY{k+kn}{import} \PY{n}{MiniBatchKMeans}
        
        
        \PY{c}{\PYZsh{}\PYZsh{} Pipeline}
        \PY{k+kn}{from} \PY{n+nn}{sklearn.pipeline} \PY{k+kn}{import} \PY{n}{Pipeline}\PY{p}{,} \PY{n}{FeatureUnion}
        
        \PY{c}{\PYZsh{}\PYZsh{} Scalers}
        \PY{k+kn}{from} \PY{n+nn}{sklearn.preprocessing} \PY{k+kn}{import} \PY{n}{StandardScaler}\PY{p}{,}\PY{n}{MinMaxScaler}\PY{p}{,}\PY{n}{Imputer}
        
        \PY{c}{\PYZsh{}\PYZsh{} Component Reduction}
        \PY{k+kn}{from} \PY{n+nn}{sklearn.lda} \PY{k+kn}{import} \PY{n}{LDA}
        \PY{k+kn}{from} \PY{n+nn}{sklearn.decomposition} \PY{k+kn}{import} \PY{n}{PCA}
        \PY{k+kn}{from} \PY{n+nn}{check} \PY{k+kn}{import} \PY{n}{output\PYZus{}classifier}
        
        \PY{c}{\PYZsh{}\PYZsh{} Scoring}
        \PY{k+kn}{from} \PY{n+nn}{sklearn.metrics} \PY{k+kn}{import} \PY{n}{recall\PYZus{}score}\PY{p}{,} \PY{n}{precision\PYZus{}score}\PY{p}{,} \PY{n}{f1\PYZus{}score}
        \PY{k+kn}{from} \PY{n+nn}{sklearn.metrics.scorer} \PY{k+kn}{import} \PY{n}{make\PYZus{}scorer}
        
        \PY{c}{\PYZsh{}\PYZsh{} Split and validation}
        \PY{k+kn}{from} \PY{n+nn}{sklearn.cross\PYZus{}validation} \PY{k+kn}{import} \PY{n}{StratifiedShuffleSplit}
        
        
        
        
        \PY{c}{\PYZsh{}\PYZsh{} Search for best parameters for classifier}
        \PY{k+kn}{from} \PY{n+nn}{sklearn.grid\PYZus{}search} \PY{k+kn}{import} \PY{n}{GridSearchCV}\PY{p}{,} \PY{n}{RandomizedSearchCV}
        
        
        \PY{n}{pd}\PY{o}{.}\PY{n}{options}\PY{o}{.}\PY{n}{display}\PY{o}{.}\PY{n}{max\PYZus{}columns} \PY{o}{=} \PY{l+m+mi}{21}
\end{Verbatim}

    Read the data and convert the data into pandas data frame.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}4}]:} \PY{n}{data\PYZus{}dict} \PY{o}{=} \PY{n}{pickle}\PY{o}{.}\PY{n}{load}\PY{p}{(}\PY{n+nb}{open}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{final\PYZus{}project\PYZus{}dataset.pkl}\PY{l+s}{\PYZdq{}}\PY{p}{,} \PY{l+s}{\PYZdq{}}\PY{l+s}{r}\PY{l+s}{\PYZdq{}}\PY{p}{)} \PY{p}{)}
        \PY{n}{df} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{o}{.}\PY{n}{from\PYZus{}dict}\PY{p}{(}\PY{n}{data\PYZus{}dict}\PY{p}{)}
        \PY{n}{df} \PY{o}{=} \PY{n}{df}\PY{o}{.}\PY{n}{transpose}\PY{p}{(}\PY{p}{)}
        \PY{n}{df}\PY{o}{.}\PY{n}{describe}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\texttt{\color{outcolor}Out[{\color{outcolor}4}]:}
    
    \centering{\begin{tabular}{llllllllllllllllllllll}
\toprule
{} & bonus & deferral\_payments & deferred\_income & director\_fees & email\_address & exercised\_stock\_options & expenses & from\_messages & from\_poi\_to\_this\_person & from\_this\_person\_to\_poi & loan\_advances & long\_term\_incentive & other &    poi & restricted\_stock & restricted\_stock\_deferred & salary & shared\_receipt\_with\_poi & to\_messages & total\_payments & total\_stock\_value \\
\midrule
count  &   146 &               146 &             146 &           146 &           146 &                     146 &      146 &           146 &                     146 &                     146 &           146 &                 146 &   146 &    146 &              146 &                       146 &    146 &                     146 &         146 &            146 &               146 \\
unique &    42 &                40 &              45 &            18 &           112 &                     102 &       95 &            65 &                      58 &                      42 &             5 &                  53 &    93 &      2 &               98 &                        19 &     95 &                      84 &          87 &            126 &               125 \\
top    &   NaN &               NaN &             NaN &           NaN &           NaN &                     NaN &      NaN &           NaN &                     NaN &                     NaN &           NaN &                 NaN &   NaN &  False &              NaN &                       NaN &    NaN &                     NaN &         NaN &            NaN &               NaN \\
freq   &    64 &               107 &              97 &           129 &            35 &                      44 &       51 &            60 &                      60 &                      60 &           142 &                  80 &    53 &    128 &               36 &                       128 &     51 &                      60 &          60 &             21 &                20 \\
\bottomrule
\end{tabular}
}

    

    A few things jump out, there appears to be 146 employees and the top
value across all the fields is `NaN'. A couple other items stand out,
only a small number received loan\_advances and paid direct fees. In
addition, only 12\% of the employees are person of interest. Based on
the size and distribution of the dataset, stratified shuffle split to
validate the precision and recall of the model.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}5}]:} \PY{n}{df}\PY{o}{.}\PY{n}{email\PYZus{}address}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{l+m+mi}{5}\PY{p}{)}
        \PY{n}{df}\PY{p}{[}\PY{n}{df}\PY{p}{[}\PY{l+s}{\PYZsq{}}\PY{l+s}{email\PYZus{}address}\PY{l+s}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{str}\PY{o}{.}\PY{n}{contains}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{enron}\PY{l+s}{\PYZdq{}}\PY{p}{)}\PY{o}{==}\PY{n+nb+bp}{False}\PY{p}{]}\PY{o}{.}\PY{n}{count}\PY{p}{(}\PY{p}{)}
\end{Verbatim}

            \begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}5}]:} bonus                        35
        deferral\_payments            35
        deferred\_income              35
        director\_fees                35
        email\_address                35
        exercised\_stock\_options      35
        expenses                     35
        from\_messages                35
        from\_poi\_to\_this\_person      35
        from\_this\_person\_to\_poi      35
        loan\_advances                35
        long\_term\_incentive          35
        other                        35
        poi                          35
        restricted\_stock             35
        restricted\_stock\_deferred    35
        salary                       35
        shared\_receipt\_with\_poi      35
        to\_messages                  35
        total\_payments               35
        total\_stock\_value            35
        dtype: int64
\end{Verbatim}
        
    Email\_address column is unquie like the employees name and doesn't
provide additional value. In addition, all email addresses in the
dataset contain enron or nan. Therefore, I choose to drop the
email\_address field.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}6}]:} \PY{n}{df}\PY{o}{.}\PY{n}{drop}\PY{p}{(}\PY{l+s}{\PYZsq{}}\PY{l+s}{email\PYZus{}address}\PY{l+s}{\PYZsq{}}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{,}\PY{n}{inplace}\PY{o}{=}\PY{n+nb+bp}{True}\PY{p}{)}
\end{Verbatim}

    Drop all employees with three or less features (3 including poi). This
includes the Travel Agency and Lockhart.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}7}]:} \PY{n}{df} \PY{o}{=} \PY{n}{df}\PY{o}{.}\PY{n}{replace}\PY{p}{(}\PY{l+s}{\PYZsq{}}\PY{l+s}{NaN}\PY{l+s}{\PYZsq{}}\PY{p}{,} \PY{n}{np}\PY{o}{.}\PY{n}{nan}\PY{p}{)}
        \PY{n}{df}\PY{o}{=}\PY{n}{df}\PY{o}{.}\PY{n}{dropna}\PY{p}{(}\PY{n}{thresh}\PY{o}{=}\PY{l+m+mi}{4}\PY{p}{,}\PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{)}
\end{Verbatim}

    Describe provides concise overview of the dataset. The first item that
jumps out\ldots{} The top value in each column is `NaN' which means the
dataset contains a significant amount of missing data.

    Let's convert the remaining fields to numbers.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}8}]:} \PY{n}{df} \PY{o}{=} \PY{n}{df}\PY{o}{.}\PY{n}{convert\PYZus{}objects}\PY{p}{(}\PY{n}{convert\PYZus{}numeric}\PY{o}{=}\PY{n+nb+bp}{True}\PY{p}{)}
        \PY{n}{df}\PY{o}{.}\PY{n}{describe}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\texttt{\color{outcolor}Out[{\color{outcolor}8}]:}
    
    \centering{\begin{tabular}{lrrrrrrrrrrrrlrrrrrrr}
\toprule
{} &            bonus &  deferral\_payments &  deferred\_income &   director\_fees &  exercised\_stock\_options &        expenses &  from\_messages &  from\_poi\_to\_this\_person &  from\_this\_person\_to\_poi &  loan\_advances &  long\_term\_incentive &            other &        poi &  restricted\_stock &  restricted\_stock\_deferred &           salary &  shared\_receipt\_with\_poi &   to\_messages &  total\_payments &  total\_stock\_value \\
\midrule
count &        82.000000 &          39.000000 &        49.000000 &       16.000000 &             9.900000e+01 &       95.000000 &      86.000000 &                86.000000 &                86.000000 &         4.0000 &            66.000000 &        91.000000 &        139 &      1.100000e+02 &                  18.000000 &        95.000000 &                86.000000 &     86.000000 &    1.220000e+02 &       1.230000e+02 \\
mean  &   2374234.609756 &     1642674.153846 &  -1140475.142857 &   169774.437500 &             6.158405e+06 &   108728.915789 &     608.790698 &                64.895349 &                41.232558 &  41962500.0000 &       1470361.454545 &    933201.791209 &  0.1294964 &      2.321741e+06 &              166410.555556 &    562194.294737 &              1176.465116 &   2073.860465 &    5.200982e+06 &       6.931067e+06 \\
std   &  10713327.969046 &     5161929.973575 &   4025406.378506 &   330140.339691 &             3.151782e+07 &   533534.814109 &    1841.033949 &                86.979244 &               100.073111 &  47083208.7019 &       5942759.315498 &   4638933.955989 &  0.3369628 &      1.251828e+07 &             4201494.314703 &   2716369.154553 &              1178.317641 &   2582.700981 &    2.940959e+07 &       3.942057e+07 \\
min   &     70000.000000 &     -102500.000000 & -27992891.000000 &     3285.000000 &             3.285000e+03 &      148.000000 &      12.000000 &                 0.000000 &                 0.000000 &    400000.0000 &         69223.000000 &         2.000000 &      False &     -2.604490e+06 &            -7576788.000000 &       477.000000 &                 2.000000 &     57.000000 &    1.480000e+02 &      -4.409300e+04 \\
25\%   &    431250.000000 &       81573.000000 &   -694862.000000 &    83674.500000 &             5.963440e+05 &    22614.000000 &      22.750000 &                10.000000 &                 1.000000 &   1600000.0000 &        281250.000000 &      1203.000000 &          0 &      2.540180e+05 &             -389621.750000 &    211816.000000 &               249.750000 &    541.250000 &    4.844302e+05 &       5.036835e+05 \\
50\%   &    769375.000000 &      227449.000000 &   -159792.000000 &   106164.500000 &             1.362375e+06 &    46950.000000 &      41.000000 &                35.000000 &                 8.000000 &  41762500.0000 &        442035.000000 &     51587.000000 &          0 &      4.517400e+05 &             -146975.000000 &    259996.000000 &               740.500000 &   1211.000000 &    1.121274e+06 &       1.118394e+06 \\
75\%   &   1200000.000000 &     1002671.500000 &    -38346.000000 &   112815.000000 &             2.576926e+06 &    79952.500000 &     145.500000 &                72.250000 &                24.750000 &  82125000.0000 &        938672.000000 &    365380.000000 &          0 &      1.002370e+06 &              -75009.750000 &    312117.000000 &              1888.250000 &   2634.750000 &    2.099339e+06 &       3.082744e+06 \\
max   &  97343619.000000 &    32083396.000000 &      -833.000000 &  1398517.000000 &             3.117640e+08 &  5235198.000000 &   14368.000000 &               528.000000 &               609.000000 &  83925000.0000 &      48521928.000000 &  42667589.000000 &       True &      1.303223e+08 &            15456290.000000 &  26704229.000000 &              5521.000000 &  15149.000000 &    3.098866e+08 &       4.345095e+08 \\
\bottomrule
\end{tabular}
}

    

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}9}]:} \PY{n}{column}\PY{o}{=}\PY{l+s}{\PYZsq{}}\PY{l+s}{salary}\PY{l+s}{\PYZsq{}}
        \PY{k}{print} \PY{n}{df}\PY{p}{[}\PY{p}{[}\PY{n}{column}\PY{p}{]}\PY{p}{]}\PY{o}{.}\PY{n}{sort}\PY{p}{(}\PY{p}{[}\PY{n}{column}\PY{p}{]}\PY{p}{,} \PY{n}{ascending}\PY{o}{=}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{)}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{l+m+mi}{3}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{figure}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{26}\PY{p}{,}\PY{l+m+mi}{6}\PY{p}{)}\PY{p}{)}
        \PY{n}{df}\PY{p}{[}\PY{n}{column}\PY{p}{]}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{style}\PY{o}{=}\PY{l+s}{\PYZsq{}}\PY{l+s}{.}\PY{l+s}{\PYZsq{}}\PY{p}{)}
        \PY{n}{x} \PY{o}{=} \PY{n+nb}{range}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{df}\PY{p}{[}\PY{n}{column}\PY{p}{]}\PY{p}{)}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{xticks}\PY{p}{(}\PY{n}{x}\PY{p}{,}\PY{n}{df}\PY{o}{.}\PY{n}{index}\PY{p}{)}
        \PY{n}{locs}\PY{p}{,} \PY{n}{labels} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{xticks}\PY{p}{(}\PY{p}{)}
        \PY{k}{print} \PY{n}{labels}
        \PY{n}{plt}\PY{o}{.}\PY{n}{setp}\PY{p}{(}\PY{n}{labels}\PY{p}{,} \PY{n}{rotation}\PY{o}{=}\PY{l+m+mi}{90}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{n}{column}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
salary
TOTAL               26704229
SKILLING JEFFREY K   1111258
LAY KENNETH L        1072321
<a list of 139 Text xticklabel objects>
    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{Enron Machine Learning Project_files/Enron Machine Learning Project_14_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    After plotting the employee salaries, it's clear the Total is an
aggregate and it should be dropped as well.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}10}]:} \PY{n}{df}\PY{o}{.}\PY{n}{drop}\PY{p}{(}\PY{l+s}{\PYZsq{}}\PY{l+s}{TOTAL}\PY{l+s}{\PYZsq{}}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{,}\PY{n}{inplace}\PY{o}{=}\PY{n+nb+bp}{True}\PY{p}{)}
\end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}11}]:} \PY{n}{column}\PY{o}{=}\PY{l+s}{\PYZsq{}}\PY{l+s}{salary}\PY{l+s}{\PYZsq{}}
         \PY{k}{print} \PY{n}{df}\PY{p}{[}\PY{p}{[}\PY{n}{column}\PY{p}{]}\PY{p}{]}\PY{o}{.}\PY{n}{sort}\PY{p}{(}\PY{p}{[}\PY{n}{column}\PY{p}{]}\PY{p}{,} \PY{n}{ascending}\PY{o}{=}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{)}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{l+m+mi}{3}\PY{p}{)}
         \PY{k}{print} \PY{n}{df}\PY{p}{[}\PY{p}{[}\PY{n}{column}\PY{p}{]}\PY{p}{]}\PY{o}{.}\PY{n}{sort}\PY{p}{(}\PY{p}{[}\PY{n}{column}\PY{p}{]}\PY{p}{,} \PY{n}{ascending}\PY{o}{=}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{)}\PY{o}{.}\PY{n}{tail}\PY{p}{(}\PY{l+m+mi}{3}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{figure}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{26}\PY{p}{,}\PY{l+m+mi}{6}\PY{p}{)}\PY{p}{)}
         \PY{n}{df}\PY{p}{[}\PY{n}{column}\PY{p}{]}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{style}\PY{o}{=}\PY{l+s}{\PYZsq{}}\PY{l+s}{.}\PY{l+s}{\PYZsq{}}\PY{p}{)}
         \PY{n}{x} \PY{o}{=} \PY{n+nb}{range}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{df}\PY{p}{[}\PY{n}{column}\PY{p}{]}\PY{p}{)}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{xticks}\PY{p}{(}\PY{n}{x}\PY{p}{,}\PY{n}{df}\PY{o}{.}\PY{n}{index}\PY{p}{)}
         \PY{n}{locs}\PY{p}{,} \PY{n}{labels} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{xticks}\PY{p}{(}\PY{p}{)}
         \PY{k}{print} \PY{n}{labels}
         \PY{n}{plt}\PY{o}{.}\PY{n}{setp}\PY{p}{(}\PY{n}{labels}\PY{p}{,} \PY{n}{rotation}\PY{o}{=}\PY{l+m+mi}{90}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{n}{column}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
salary
SKILLING JEFFREY K  1111258
LAY KENNETH L       1072321
FREVERT MARK A      1060932
                       salary
WALTERS GARETH W          NaN
WINOKUR JR. HERBERT S     NaN
YEAP SOON                 NaN
<a list of 138 Text xticklabel objects>
    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{Enron Machine Learning Project_files/Enron Machine Learning Project_17_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    Now, we'll fill any NaNs with the mean\ldots{}. I tried using Imputer
but the model didn't perform as well.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}12}]:} \PY{n}{df} \PY{o}{=} \PY{n}{df}\PY{o}{.}\PY{n}{apply}\PY{p}{(}\PY{k}{lambda} \PY{n}{x}\PY{p}{:} \PY{n}{x}\PY{o}{.}\PY{n}{fillna}\PY{p}{(}\PY{n}{x}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{p}{)}\PY{p}{)}\PY{p}{,}\PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{)}
\end{Verbatim}

    Next, we'll review the scatter plot for salary vs bonus,
exercised\_stock\_options vs total\_payments. Please see the
final\_project\_plots.html to review all plots.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}13}]:} \PY{n}{df}\PY{o}{.}\PY{n}{loc}\PY{p}{[}\PY{n}{df}\PY{p}{[}\PY{l+s}{\PYZsq{}}\PY{l+s}{poi}\PY{l+s}{\PYZsq{}}\PY{p}{]} \PY{o}{==} \PY{n+nb+bp}{True}\PY{p}{,} \PY{l+s}{\PYZsq{}}\PY{l+s}{color}\PY{l+s}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{l+s}{\PYZsq{}}\PY{l+s}{r}\PY{l+s}{\PYZsq{}}
         \PY{n}{df}\PY{o}{.}\PY{n}{loc}\PY{p}{[}\PY{n}{df}\PY{p}{[}\PY{l+s}{\PYZsq{}}\PY{l+s}{poi}\PY{l+s}{\PYZsq{}}\PY{p}{]} \PY{o}{==} \PY{n+nb+bp}{False}\PY{p}{,} \PY{l+s}{\PYZsq{}}\PY{l+s}{color}\PY{l+s}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{l+s}{\PYZsq{}}\PY{l+s}{b}\PY{l+s}{\PYZsq{}}
         \PY{n}{plt}\PY{o}{.}\PY{n}{scatter}\PY{p}{(}\PY{n}{x}\PY{o}{=}\PY{n}{df}\PY{p}{[}\PY{l+s}{\PYZsq{}}\PY{l+s}{salary}\PY{l+s}{\PYZsq{}}\PY{p}{]}\PY{p}{,}\PY{n}{y}\PY{o}{=}\PY{n}{df}\PY{p}{[}\PY{l+s}{\PYZsq{}}\PY{l+s}{bonus}\PY{l+s}{\PYZsq{}}\PY{p}{]}\PY{p}{,}\PY{n}{c}\PY{o}{=}\PY{n}{df}\PY{p}{[}\PY{l+s}{\PYZsq{}}\PY{l+s}{color}\PY{l+s}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s}{\PYZsq{}}\PY{l+s}{Salary vs Bonus}\PY{l+s}{\PYZsq{}}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s}{\PYZsq{}}\PY{l+s}{Salary}\PY{l+s}{\PYZsq{}}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s}{\PYZsq{}}\PY{l+s}{Bonus}\PY{l+s}{\PYZsq{}}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{Enron Machine Learning Project_files/Enron Machine Learning Project_21_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}14}]:} \PY{n}{plt}\PY{o}{.}\PY{n}{scatter}\PY{p}{(}\PY{n}{x}\PY{o}{=}\PY{n}{df}\PY{p}{[}\PY{l+s}{\PYZsq{}}\PY{l+s}{exercised\PYZus{}stock\PYZus{}options}\PY{l+s}{\PYZsq{}}\PY{p}{]}\PY{p}{,}\PY{n}{y}\PY{o}{=}\PY{n}{df}\PY{p}{[}\PY{l+s}{\PYZsq{}}\PY{l+s}{total\PYZus{}payments}\PY{l+s}{\PYZsq{}}\PY{p}{]}\PY{p}{,}\PY{n}{c}\PY{o}{=}\PY{n}{df}\PY{p}{[}\PY{l+s}{\PYZsq{}}\PY{l+s}{color}\PY{l+s}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s}{\PYZsq{}}\PY{l+s}{Exercised Stock Options vs Total Stock Value}\PY{l+s}{\PYZsq{}}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s}{\PYZsq{}}\PY{l+s}{Exercised Stock Options}\PY{l+s}{\PYZsq{}}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s}{\PYZsq{}}\PY{l+s}{Total Stock Value}\PY{l+s}{\PYZsq{}}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{Enron Machine Learning Project_files/Enron Machine Learning Project_22_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}15}]:} \PY{n}{df}\PY{o}{.}\PY{n}{drop}\PY{p}{(}\PY{l+s}{\PYZsq{}}\PY{l+s}{color}\PY{l+s}{\PYZsq{}}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{inplace}\PY{o}{=}\PY{n+nb+bp}{True}\PY{p}{)}
\end{Verbatim}

    First, I created a new feature to\_poi\_ratio. My belief is sending a
high number emails to a POI likely means the person is also involved in
fruad. Next, let's determine which feature should be included in the
model.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}16}]:} \PY{n}{df}\PY{p}{[}\PY{l+s}{\PYZsq{}}\PY{l+s}{to\PYZus{}poi\PYZus{}ratio}\PY{l+s}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{df}\PY{p}{[}\PY{l+s}{\PYZsq{}}\PY{l+s}{from\PYZus{}this\PYZus{}person\PYZus{}to\PYZus{}poi}\PY{l+s}{\PYZsq{}}\PY{p}{]}\PY{o}{/}\PY{n}{df}\PY{p}{[}\PY{l+s}{\PYZsq{}}\PY{l+s}{from\PYZus{}messages}\PY{l+s}{\PYZsq{}}\PY{p}{]}
         
         \PY{n}{features\PYZus{}list} \PY{o}{=} \PY{p}{[}\PY{l+s}{\PYZsq{}}\PY{l+s}{poi}\PY{l+s}{\PYZsq{}}
                          \PY{p}{,} \PY{l+s}{\PYZsq{}}\PY{l+s}{bonus}\PY{l+s}{\PYZsq{}}
                          \PY{p}{,} \PY{l+s}{\PYZsq{}}\PY{l+s}{deferral\PYZus{}payments}\PY{l+s}{\PYZsq{}}
                          \PY{p}{,} \PY{l+s}{\PYZsq{}}\PY{l+s}{deferred\PYZus{}income}\PY{l+s}{\PYZsq{}}
                          \PY{p}{,} \PY{l+s}{\PYZsq{}}\PY{l+s}{director\PYZus{}fees}\PY{l+s}{\PYZsq{}}
                          \PY{p}{,} \PY{l+s}{\PYZsq{}}\PY{l+s}{exercised\PYZus{}stock\PYZus{}options}\PY{l+s}{\PYZsq{}}
                          \PY{p}{,} \PY{l+s}{\PYZsq{}}\PY{l+s}{expenses}\PY{l+s}{\PYZsq{}}
                          \PY{p}{,} \PY{l+s}{\PYZsq{}}\PY{l+s}{from\PYZus{}messages}\PY{l+s}{\PYZsq{}}
                          \PY{p}{,} \PY{l+s}{\PYZsq{}}\PY{l+s}{from\PYZus{}poi\PYZus{}to\PYZus{}this\PYZus{}person}\PY{l+s}{\PYZsq{}}
                          \PY{p}{,} \PY{l+s}{\PYZsq{}}\PY{l+s}{from\PYZus{}this\PYZus{}person\PYZus{}to\PYZus{}poi}\PY{l+s}{\PYZsq{}}
                          \PY{p}{,} \PY{l+s}{\PYZsq{}}\PY{l+s}{loan\PYZus{}advances}\PY{l+s}{\PYZsq{}}
                          \PY{p}{,} \PY{l+s}{\PYZsq{}}\PY{l+s}{long\PYZus{}term\PYZus{}incentive}\PY{l+s}{\PYZsq{}}
                          \PY{p}{,} \PY{l+s}{\PYZsq{}}\PY{l+s}{other}\PY{l+s}{\PYZsq{}}
                          \PY{p}{,} \PY{l+s}{\PYZsq{}}\PY{l+s}{restricted\PYZus{}stock}\PY{l+s}{\PYZsq{}}
                          \PY{p}{,} \PY{l+s}{\PYZsq{}}\PY{l+s}{restricted\PYZus{}stock\PYZus{}deferred}\PY{l+s}{\PYZsq{}}
                          \PY{p}{,} \PY{l+s}{\PYZsq{}}\PY{l+s}{salary}\PY{l+s}{\PYZsq{}}
                          \PY{p}{,} \PY{l+s}{\PYZsq{}}\PY{l+s}{shared\PYZus{}receipt\PYZus{}with\PYZus{}poi}\PY{l+s}{\PYZsq{}}
                          \PY{p}{,} \PY{l+s}{\PYZsq{}}\PY{l+s}{to\PYZus{}messages}\PY{l+s}{\PYZsq{}}
                          \PY{p}{,} \PY{l+s}{\PYZsq{}}\PY{l+s}{total\PYZus{}payments}\PY{l+s}{\PYZsq{}}
                          \PY{p}{,} \PY{l+s}{\PYZsq{}}\PY{l+s}{total\PYZus{}stock\PYZus{}value}\PY{l+s}{\PYZsq{}}
                          \PY{p}{,} \PY{l+s}{\PYZsq{}}\PY{l+s}{to\PYZus{}poi\PYZus{}ratio}\PY{l+s}{\PYZsq{}}\PY{p}{]}
         
         \PY{n}{my\PYZus{}dataset} \PY{o}{=} \PY{n}{df}\PY{o}{.}\PY{n}{T}\PY{o}{.}\PY{n}{to\PYZus{}dict}\PY{p}{(}\PY{l+s}{\PYZsq{}}\PY{l+s}{dict}\PY{l+s}{\PYZsq{}}\PY{p}{)}
         
         \PY{c}{\PYZsh{}\PYZsh{}\PYZsh{} Extract features and labels from dataset for local testing}
         \PY{n}{data} \PY{o}{=} \PY{n}{featureFormat}\PY{p}{(}\PY{n}{my\PYZus{}dataset}\PY{p}{,} \PY{n}{features\PYZus{}list}\PY{p}{,} \PY{n}{sort\PYZus{}keys} \PY{o}{=} \PY{n+nb+bp}{True}\PY{p}{)}
         \PY{n}{labels}\PY{p}{,} \PY{n}{features} \PY{o}{=} \PY{n}{targetFeatureSplit}\PY{p}{(}\PY{n}{data}\PY{p}{)}
\end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}29}]:} \PY{n}{names} \PY{o}{=} \PY{p}{[}
            \PY{l+s}{\PYZdq{}}\PY{l+s}{Linear\PYZus{}SVC}\PY{l+s}{\PYZdq{}}\PY{p}{,}
            \PY{l+s}{\PYZdq{}}\PY{l+s}{Naive\PYZus{}Bayes}\PY{l+s}{\PYZdq{}}\PY{p}{,}
            \PY{l+s}{\PYZdq{}}\PY{l+s}{KNeighborsClassifier}\PY{l+s}{\PYZdq{}}\PY{p}{,}
            \PY{l+s}{\PYZdq{}}\PY{l+s}{DecisionTreeClassifier}\PY{l+s}{\PYZdq{}}
            \PY{p}{]}
         
         \PY{n}{classifiers} \PY{o}{=} \PY{p}{[}
             \PY{n}{LinearSVC}\PY{p}{(}\PY{p}{)}\PY{p}{,}
             \PY{n}{GaussianNB}\PY{p}{(}\PY{p}{)}\PY{p}{,}
             \PY{n}{KNeighborsClassifier}\PY{p}{(}\PY{n}{n\PYZus{}neighbors}\PY{o}{=}\PY{l+m+mi}{2}\PY{p}{)}\PY{p}{,}
             \PY{n}{DecisionTreeClassifier}\PY{p}{(}\PY{p}{)}
             \PY{p}{]}
         
         \PY{k}{for} \PY{n}{name}\PY{p}{,} \PY{n}{classifier} \PY{o+ow}{in} \PY{n+nb}{zip}\PY{p}{(}\PY{n}{names}\PY{p}{,} \PY{n}{classifiers}\PY{p}{)}\PY{p}{:}
             \pagebreak
             \PY{k}{print} \PY{l+s}{\PYZdq{}}\PY{l+s}{\PYZob{}\PYZcb{} Percent Recall/Precsiion for Features}\PY{l+s}{\PYZdq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{name}\PY{p}{)}
             \PY{n}{results} \PY{o}{=} \PY{p}{\PYZob{}}\PY{p}{\PYZcb{}}
             \PY{k}{for} \PY{n}{i} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,}\PY{n+nb}{len}\PY{p}{(}\PY{n}{features\PYZus{}list}\PY{p}{)}\PY{p}{)}\PY{p}{:}
         
                 \PY{n}{clf} \PY{o}{=} \PY{n}{Pipeline}\PY{p}{(}\PY{p}{[}
                    \PY{p}{(}\PY{l+s}{\PYZsq{}}\PY{l+s}{scaler}\PY{l+s}{\PYZsq{}}\PY{p}{,} \PY{n}{StandardScaler}\PY{p}{(}\PY{p}{)}\PY{p}{)}\PY{p}{,}
                    \PY{p}{(}\PY{l+s}{\PYZsq{}}\PY{l+s}{kbest}\PY{l+s}{\PYZsq{}}\PY{p}{,} \PY{n}{SelectKBest}\PY{p}{(}\PY{n}{k}\PY{o}{=}\PY{n}{i}\PY{p}{)}\PY{p}{)}\PY{p}{,}
                    \PY{p}{(}\PY{l+s}{\PYZsq{}}\PY{l+s}{classifier}\PY{l+s}{\PYZsq{}}\PY{p}{,} \PY{n}{classifier}\PY{p}{)}\PY{p}{,}
                 \PY{p}{]}\PY{p}{)}
                 \PY{n}{results}\PY{p}{[}\PY{n}{i}\PY{p}{]} \PY{o}{=} \PY{n}{output\PYZus{}classifier}\PY{p}{(} \PY{n}{clf}\PY{p}{,} \PY{n}{my\PYZus{}dataset}\PY{p}{,} \PY{n}{features\PYZus{}list}\PY{p}{,} \PY{n}{folds} \PY{o}{=} \PY{l+m+mi}{100}\PY{p}{)}
         
             \PY{n}{accuracy\PYZus{}array}  \PY{o}{=} \PY{p}{[}\PY{p}{]}
             \PY{n}{recall\PYZus{}array}    \PY{o}{=} \PY{p}{[}\PY{p}{]}
             \PY{n}{precision\PYZus{}array} \PY{o}{=} \PY{p}{[}\PY{p}{]} 
             \PY{n}{f1\PYZus{}array}        \PY{o}{=} \PY{p}{[}\PY{p}{]} 
             \PY{n}{f2\PYZus{}array}        \PY{o}{=} \PY{p}{[}\PY{p}{]}
             \PY{n}{kbest}           \PY{o}{=} \PY{p}{[}\PY{p}{]}
         
             \PY{k}{for} \PY{n}{i} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,}\PY{n+nb}{len}\PY{p}{(}\PY{n}{features\PYZus{}list}\PY{p}{)}\PY{p}{)}\PY{p}{:}
                \PY{n}{accuracy\PYZus{}array}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{results}\PY{p}{[}\PY{n}{i}\PY{p}{]}\PY{p}{[}\PY{l+s}{\PYZsq{}}\PY{l+s}{accuracy}\PY{l+s}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
                \PY{n}{recall\PYZus{}array}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{results}\PY{p}{[}\PY{n}{i}\PY{p}{]}\PY{p}{[}\PY{l+s}{\PYZsq{}}\PY{l+s}{recall}\PY{l+s}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
                \PY{n}{precision\PYZus{}array}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{results}\PY{p}{[}\PY{n}{i}\PY{p}{]}\PY{p}{[}\PY{l+s}{\PYZsq{}}\PY{l+s}{precision}\PY{l+s}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
                \PY{n}{f1\PYZus{}array}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{results}\PY{p}{[}\PY{n}{i}\PY{p}{]}\PY{p}{[}\PY{l+s}{\PYZsq{}}\PY{l+s}{f1}\PY{l+s}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
                \PY{n}{f2\PYZus{}array}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{results}\PY{p}{[}\PY{n}{i}\PY{p}{]}\PY{p}{[}\PY{l+s}{\PYZsq{}}\PY{l+s}{f2}\PY{l+s}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
                \PY{n}{kbest}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{i}\PY{p}{)}
         
             \PY{n}{kbest\PYZus{}df} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n}{results}\PY{p}{)}\PY{o}{.}\PY{n}{transpose}\PY{p}{(}\PY{p}{)}
             \PY{n}{kbest\PYZus{}df}   
         
             \PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{kbest}\PY{p}{,} \PY{n}{recall\PYZus{}array}\PY{p}{,} \PY{n}{color}\PY{o}{=}\PY{l+s}{\PYZsq{}}\PY{l+s}{r}\PY{l+s}{\PYZsq{}}\PY{p}{,} \PY{n}{label}\PY{o}{=}\PY{l+s}{\PYZsq{}}\PY{l+s}{recall}\PY{l+s}{\PYZsq{}}\PY{p}{)}
             \PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{kbest}\PY{p}{,} \PY{n}{precision\PYZus{}array}\PY{p}{,} \PY{n}{color}\PY{o}{=}\PY{l+s}{\PYZsq{}}\PY{l+s}{b}\PY{l+s}{\PYZsq{}}\PY{p}{,} \PY{n}{label}\PY{o}{=}\PY{l+s}{\PYZsq{}}\PY{l+s}{precision}\PY{l+s}{\PYZsq{}}\PY{p}{)}
             \PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{kbest}\PY{p}{,} \PY{n}{f1\PYZus{}array}\PY{p}{,} \PY{n}{color}\PY{o}{=}\PY{l+s}{\PYZsq{}}\PY{l+s}{g}\PY{l+s}{\PYZsq{}}\PY{p}{,} \PY{n}{label}\PY{o}{=}\PY{l+s}{\PYZsq{}}\PY{l+s}{f1}\PY{l+s}{\PYZsq{}}\PY{p}{)}
             \PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s}{\PYZsq{}}\PY{l+s}{Features}\PY{l+s}{\PYZsq{}}\PY{p}{)}
             \PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s}{\PYZsq{}}\PY{l+s}{Percent}\PY{l+s}{\PYZsq{}}\PY{p}{)}
             \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(} \PY{l+s}{\PYZdq{}}\PY{l+s}{\PYZob{}\PYZcb{} Percent Recall/Precsiion for Features}\PY{l+s}{\PYZdq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{name}\PY{p}{)}\PY{p}{)}
             \PY{n}{plt}\PY{o}{.}\PY{n}{legend}\PY{p}{(}\PY{p}{)}
             \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
             
\end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
Linear\_SVC Percent Recall/Precsiion for Features
    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{Enron Machine Learning Project_files/Enron Machine Learning Project_26_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
Naive\_Bayes Percent Recall/Precsiion for Features
    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{Enron Machine Learning Project_files/Enron Machine Learning Project_26_3.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
KNeighborsClassifier Percent Recall/Precsiion for Features
    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{Enron Machine Learning Project_files/Enron Machine Learning Project_26_5.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
DecisionTreeClassifier Percent Recall/Precsiion for Features
    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{Enron Machine Learning Project_files/Enron Machine Learning Project_26_7.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    Using selectkbest and the plots found in final\_project\_plots.html, I
selected the following features for my initial model.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}18}]:} \PY{n}{features} \PY{o}{=} \PY{n}{StandardScaler}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{fit\PYZus{}transform}\PY{p}{(}\PY{n}{features}\PY{p}{)}
         \PY{n}{selector} \PY{o}{=} \PY{n}{SelectKBest}\PY{p}{(}\PY{n}{k}\PY{o}{=}\PY{l+m+mi}{5}\PY{p}{)}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{features}\PY{p}{,} \PY{n}{labels}\PY{p}{)}\PY{o}{.}\PY{n}{scores\PYZus{}}
         \PY{k}{for} \PY{n}{score}\PY{p}{,} \PY{n}{feature} \PY{o+ow}{in} \PY{n+nb}{sorted}\PY{p}{(}\PY{n+nb}{zip}\PY{p}{(}\PY{n}{selector}\PY{p}{,} \PY{n}{features\PYZus{}list}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{:}\PY{p}{]}\PY{p}{)}\PY{p}{,} \PY{n}{reverse}\PY{o}{=}\PY{n+nb+bp}{True}\PY{p}{)}\PY{p}{:}
             \PY{k}{print} \PY{n}{feature}\PY{p}{,} \PY{n}{score}
\end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
exercised\_stock\_options 27.6300165058
total\_stock\_value 20.2386111807
to\_poi\_ratio 15.3323918413
bonus 11.0278729552
salary 9.06155550947
total\_payments 7.3433576332
restricted\_stock 6.60730691505
loan\_advances 6.04841019442
long\_term\_incentive 5.74943809023
shared\_receipt\_with\_poi 5.524340357
deferred\_income 5.40792037439
from\_poi\_to\_this\_person 2.92653569833
other 1.80626877577
from\_this\_person\_to\_poi 1.31157326324
from\_messages 0.564677533178
expenses 0.461224464842
deferral\_payments 0.366498924661
to\_messages 0.35488527817
director\_fees 1.23951588535e-31
restricted\_stock\_deferred 3.94738593348e-32
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}19}]:} \PY{n}{features\PYZus{}list} \PY{o}{=} \PY{p}{[}\PY{l+s}{\PYZsq{}}\PY{l+s}{poi}\PY{l+s}{\PYZsq{}}
                         \PY{p}{,}\PY{l+s}{\PYZsq{}}\PY{l+s}{exercised\PYZus{}stock\PYZus{}options}\PY{l+s}{\PYZsq{}} 
                         \PY{p}{,}\PY{l+s}{\PYZsq{}}\PY{l+s}{total\PYZus{}stock\PYZus{}value}\PY{l+s}{\PYZsq{}} 
                         \PY{p}{,}\PY{l+s}{\PYZsq{}}\PY{l+s}{to\PYZus{}poi\PYZus{}ratio}\PY{l+s}{\PYZsq{}}
                         \PY{p}{,}\PY{l+s}{\PYZsq{}}\PY{l+s}{bonus}\PY{l+s}{\PYZsq{}}
                         \PY{p}{,}\PY{l+s}{\PYZsq{}}\PY{l+s}{salary}\PY{l+s}{\PYZsq{}}
                         \PY{p}{]}
         
         \PY{n}{my\PYZus{}dataset} \PY{o}{=} \PY{n}{df}\PY{o}{.}\PY{n}{T}\PY{o}{.}\PY{n}{to\PYZus{}dict}\PY{p}{(}\PY{l+s}{\PYZsq{}}\PY{l+s}{dict}\PY{l+s}{\PYZsq{}}\PY{p}{)}
         
         \PY{c}{\PYZsh{}\PYZsh{}\PYZsh{} Extract features and labels from dataset for local testing}
         \PY{n}{data} \PY{o}{=} \PY{n}{featureFormat}\PY{p}{(}\PY{n}{my\PYZus{}dataset}\PY{p}{,} \PY{n}{features\PYZus{}list}\PY{p}{,} \PY{n}{sort\PYZus{}keys} \PY{o}{=} \PY{n+nb+bp}{True}\PY{p}{)}
         \PY{n}{labels}\PY{p}{,} \PY{n}{features} \PY{o}{=} \PY{n}{targetFeatureSplit}\PY{p}{(}\PY{n}{data}\PY{p}{)}
\end{Verbatim}

    \section{Analysis Validation and
Performance}\label{analysis-validation-and-performance}

    Using an example for the sklearn documenation, I decided to test
LinearSVC and GaussianNB using Principal Component Analysis (PCA) and .
Principal Component Analysis (PCA) anad Linear Discriminant Analysis
(LDA). PCA identifies the combination of attributes (principal
components, or directions in the feature space) that account for the
most variance in the data. Linear Discriminant Analysis (LDA) tries to
identify attributes that account for the most variance between classes.
In particular, LDA, in contrast to PCA, is a supervised method, using
known class labels.

http://scikit-learn.org/stable/auto\_examples/decomposition/plot\_pca\_vs\_lda.html

Based on the size and distribution of the dataset, Sklearn's
StratifiedShuffleSplit function was used to perform validation and
capture performance measures. For 1000 folds, StratifiedShuffleSplit
splits the dataset into two parts: training and testing sets. First, the
training dataset is passed to the algorithm using fit. Then, the test
dataset is passed to predict. Last, the results of predict is evaluated
for each employee to determine if the outcome is a true positive, true
negative, false positive, or false negative. After all 1000 folds are
completed, the precision and recall is calculated.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}20}]:} \PY{c}{\PYZsh{}\PYZsh{}\PYZsh{} Task 4: Try a varity of classifiers}
         \PY{c}{\PYZsh{}\PYZsh{}\PYZsh{} Please name your classifier clf for easy export below.}
         \PY{c}{\PYZsh{}\PYZsh{}\PYZsh{} Note that if you want to do PCA or other multi\PYZhy{}stage operations,}
         \PY{c}{\PYZsh{}\PYZsh{}\PYZsh{} you\PYZsq{}ll need to use Pipelines. For more info:}
         \PY{c}{\PYZsh{}\PYZsh{}\PYZsh{} http://scikit\PYZhy{}learn.org/stable/modules/pipeline.html}
         \PY{n}{dict\PYZus{}all} \PY{o}{=} \PY{p}{\PYZob{}}\PY{p}{\PYZcb{}}
         \PY{n}{dict\PYZus{}pca} \PY{o}{=} \PY{p}{\PYZob{}}\PY{p}{\PYZcb{}}
         \PY{n}{dict\PYZus{}lda} \PY{o}{=} \PY{p}{\PYZob{}}\PY{p}{\PYZcb{}}
\end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}21}]:} \PY{k}{print} \PY{l+s}{\PYZdq{}}\PY{l+s}{With StandardScaler}\PY{l+s}{\PYZdq{}}
         \PY{k}{for} \PY{n}{name}\PY{p}{,} \PY{n}{clf} \PY{o+ow}{in} \PY{n+nb}{zip}\PY{p}{(}\PY{n}{names}\PY{p}{,} \PY{n}{classifiers}\PY{p}{)}\PY{p}{:}
             \PY{n}{clf\PYZus{}all} \PY{o}{=} \PY{n}{Pipeline}\PY{p}{(}\PY{n}{steps}\PY{o}{=}\PY{p}{[}
                \PY{p}{(}\PY{l+s}{\PYZsq{}}\PY{l+s}{scaler}\PY{l+s}{\PYZsq{}}\PY{p}{,} \PY{n}{StandardScaler}\PY{p}{(}\PY{p}{)}\PY{p}{)}\PY{p}{,}
                \PY{p}{(}\PY{l+s}{\PYZsq{}}\PY{l+s}{classification}\PY{l+s}{\PYZsq{}}\PY{p}{,} \PY{n}{clf}\PY{p}{)}
             \PY{p}{]}\PY{p}{)}
             \PY{n}{dict\PYZus{}all}\PY{p}{[}\PY{n}{name}\PY{p}{]} \PY{o}{=}  \PY{n}{output\PYZus{}classifier}\PY{p}{(}\PY{n}{clf\PYZus{}all}\PY{p}{,} \PY{n}{my\PYZus{}dataset}\PY{p}{,} \PY{n}{features\PYZus{}list}\PY{p}{)}
         \PY{n+nb}{all} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{o}{.}\PY{n}{from\PYZus{}dict}\PY{p}{(}\PY{n}{dict\PYZus{}all}\PY{p}{,} \PY{n}{orient}\PY{o}{=}\PY{l+s}{\PYZsq{}}\PY{l+s}{index}\PY{l+s}{\PYZsq{}}\PY{p}{)}
         \PY{n+nb}{all} 
\end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
With StandardScaler
    \end{Verbatim}
\texttt{\color{outcolor}Out[{\color{outcolor}21}]:}
    
    \centering{\begin{tabular}{lrrrrr}
\toprule
{} &  recall &        f1 &        f2 &  precision &  accuracy \\
\midrule
DecisionTreeClassifier &  0.2420 &  0.242850 &  0.242339 &   0.243706 &  0.784429 \\
KNeighborsClassifier   &  0.0795 &  0.121560 &  0.092270 &   0.258117 &  0.835857 \\
Linear\_SVC             &  0.2335 &  0.336334 &  0.266036 &   0.601030 &  0.868357 \\
Naive\_Bayes            &  0.3105 &  0.378197 &  0.334446 &   0.483645 &  0.854143 \\
\bottomrule
\end{tabular}
}

    

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}22}]:} \PY{k}{print} \PY{l+s}{\PYZdq{}}\PY{l+s}{With StandardScaler and PCA}\PY{l+s}{\PYZdq{}}
         \PY{k}{for} \PY{n}{name}\PY{p}{,} \PY{n}{clf} \PY{o+ow}{in} \PY{n+nb}{zip}\PY{p}{(}\PY{n}{names}\PY{p}{,} \PY{n}{classifiers}\PY{p}{)}\PY{p}{:}
             \PY{n}{clf\PYZus{}pca} \PY{o}{=} \PY{n}{Pipeline}\PY{p}{(}\PY{n}{steps}\PY{o}{=}\PY{p}{[}
                \PY{p}{(}\PY{l+s}{\PYZsq{}}\PY{l+s}{scaler}\PY{l+s}{\PYZsq{}}\PY{p}{,} \PY{n}{StandardScaler}\PY{p}{(}\PY{p}{)}\PY{p}{)}\PY{p}{,}
                \PY{p}{(}\PY{l+s}{\PYZsq{}}\PY{l+s}{reduce\PYZus{}dim}\PY{l+s}{\PYZsq{}}\PY{p}{,} \PY{n}{PCA}\PY{p}{(}\PY{n}{n\PYZus{}components}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}\PY{p}{,}
                \PY{p}{(}\PY{l+s}{\PYZsq{}}\PY{l+s}{classification}\PY{l+s}{\PYZsq{}}\PY{p}{,} \PY{n}{clf}\PY{p}{)}
              \PY{p}{]}\PY{p}{)}
             \PY{n}{dict\PYZus{}pca}\PY{p}{[}\PY{n}{name}\PY{p}{]} \PY{o}{=}  \PY{n}{output\PYZus{}classifier}\PY{p}{(}\PY{n}{clf\PYZus{}pca}\PY{p}{,} \PY{n}{my\PYZus{}dataset}\PY{p}{,} \PY{n}{features\PYZus{}list}\PY{p}{)}
         \PY{n}{pca} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{o}{.}\PY{n}{from\PYZus{}dict}\PY{p}{(}\PY{n}{dict\PYZus{}pca}\PY{p}{,} \PY{n}{orient}\PY{o}{=}\PY{l+s}{\PYZsq{}}\PY{l+s}{index}\PY{l+s}{\PYZsq{}}\PY{p}{)}
         \PY{n}{pca}
\end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
With StandardScaler and PCA
    \end{Verbatim}
\texttt{\color{outcolor}Out[{\color{outcolor}22}]:}
    
    \centering{\begin{tabular}{lrrrrr}
\toprule
{} &  recall &        f1 &        f2 &  precision &  accuracy \\
\midrule
DecisionTreeClassifier &  0.3565 &  0.356233 &  0.356393 &   0.355966 &  0.815929 \\
KNeighborsClassifier   &  0.1700 &  0.258555 &  0.196987 &   0.539683 &  0.860714 \\
Linear\_SVC             &  0.2190 &  0.334224 &  0.254031 &   0.705314 &  0.875357 \\
Naive\_Bayes            &  0.2275 &  0.328283 &  0.259348 &   0.589378 &  0.867000 \\
\bottomrule
\end{tabular}
}

    

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}23}]:} \PY{k}{print} \PY{l+s}{\PYZdq{}}\PY{l+s}{With StandardScaler and LDA}\PY{l+s}{\PYZdq{}}
         \PY{k}{for} \PY{n}{name}\PY{p}{,} \PY{n}{clf} \PY{o+ow}{in} \PY{n+nb}{zip}\PY{p}{(}\PY{n}{names}\PY{p}{,} \PY{n}{classifiers}\PY{p}{)}\PY{p}{:}
             \PY{n}{clf\PYZus{}lda} \PY{o}{=} \PY{n}{Pipeline}\PY{p}{(}\PY{n}{steps}\PY{o}{=}\PY{p}{[}
                \PY{c}{\PYZsh{}(\PYZsq{}scaler\PYZsq{}, StandardScaler()),}
                \PY{p}{(}\PY{l+s}{\PYZsq{}}\PY{l+s}{reduce\PYZus{}dim}\PY{l+s}{\PYZsq{}}\PY{p}{,} \PY{n}{LDA}\PY{p}{(}\PY{n}{n\PYZus{}components}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}\PY{p}{,}
                \PY{p}{(}\PY{l+s}{\PYZsq{}}\PY{l+s}{classification}\PY{l+s}{\PYZsq{}}\PY{p}{,} \PY{n}{clf}\PY{p}{)}
             \PY{p}{]}\PY{p}{)}
             \PY{n}{dict\PYZus{}lda}\PY{p}{[}\PY{n}{name}\PY{p}{]} \PY{o}{=}  \PY{n}{output\PYZus{}classifier}\PY{p}{(}\PY{n}{clf\PYZus{}lda}\PY{p}{,} \PY{n}{my\PYZus{}dataset}\PY{p}{,} \PY{n}{features\PYZus{}list}\PY{p}{)}
         \PY{n}{lda} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{o}{.}\PY{n}{from\PYZus{}dict}\PY{p}{(}\PY{n}{dict\PYZus{}lda}\PY{p}{,} \PY{n}{orient}\PY{o}{=}\PY{l+s}{\PYZsq{}}\PY{l+s}{index}\PY{l+s}{\PYZsq{}}\PY{p}{)}
         \PY{n}{lda}
\end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
With StandardScaler and LDA
    \end{Verbatim}
\texttt{\color{outcolor}Out[{\color{outcolor}23}]:}
    
    \centering{\begin{tabular}{lrrrrr}
\toprule
{} &  recall &        f1 &        f2 &  precision &  accuracy \\
\midrule
DecisionTreeClassifier &  0.3415 &  0.358154 &  0.347972 &   0.376516 &  0.825143 \\
KNeighborsClassifier   &  0.1835 &  0.273472 &  0.211308 &   0.536550 &  0.860714 \\
Linear\_SVC             &  0.2375 &  0.339893 &  0.270040 &   0.597484 &  0.868214 \\
Naive\_Bayes            &  0.3275 &  0.400857 &  0.353366 &   0.516562 &  0.860143 \\
\bottomrule
\end{tabular}
}

    

    Using the features selected, I wasn't able build a model with recall and
precision great than 30\%. Next, I'll attempt to use performance tuning
to build a model that meets the 30/30 goal.

    \section{Performance Tuning and Validation\ldots{} why it's
important}\label{performance-tuning-and-validation-why-its-important}

    John Meyers, in a stack overflow post, defined performance tuning as the
following, In the abstract sense of machine learning, tuning is working
with / ``learning from'' variable data based on some parameters which
have been identified to affect system performance as evaluated by some
appropriate1 metric. Improved performance reveals which parameter
settings are more favorable (tuned) or less favorable (untuned).
Translating this into common sense, tuning is essentially selecting the
best parameters for an algorithm to optimize its performance given a
working environment such as hardware, specific workloads, etc. And
tuning in machine learning is an automated process for doing this.

To put performance tuning into even simpler terms, Performance tuning in
machine learning is similar to performance tuning your car. In car, you
might put in new spark plugs, brake pads, exhaust system, or computer
chip to make the car accelerate or stop more quickly. In machine
learning, performance tuning is the ability to increase the performance,
in this case precise and recall, without additional data.

Cross-validation definition from Wikipedia: Cross-validation, sometimes
called rotation estimation,is a model validation technique for assessing
how the results of a statistical analysis will generalize to an
independent data set. It is mainly used in settings where the goal is
prediction, and one wants to estimate how accurately a predictive model
will perform in practice. In a prediction problem, a model is usually
given a dataset of known data on which training is run (training
dataset), and a dataset of unknown data (or first seen data) against
which the model is tested (testing dataset). The goal of cross
validation is to define a dataset to ``test'' the model in the training
phase (i.e., the validation dataset), in order to limit problems like
overfitting, give an insight on how the model will generalize to an
independent dataset (i.e., an unknown dataset, for instance from a real
problem), etc.

One round of cross-validation involves partitioning a sample of data
into complementary subsets, performing the analysis on one subset
(called the training set), and validating the analysis on the other
subset (called the validation set or testing set). To reduce
variability, multiple rounds of cross-validation are performed using
different partitions, and the validation results are averaged over the
rounds.

Cross-validation is important in guarding against testing hypotheses
suggested by the data, especially where further samples are hazardous,
costly or impossible to collect.

Furthermore, one of the main reasons for using cross-validation instead
of using the conventional validation (e.g.~partitioning the data set
into two sets of 70\% for training and 30\% for test) is that the error
(e.g.~Root Mean Square Error) on the training set in the conventional
validation is not a useful estimator of model performance and thus the
error on the test data set does not properly represent the assessment of
model performance. This may be because there is not enough data
available or there is not a good distribution and spread of data to
partition it into separate training and test sets in the conventional
validation method. In these cases, a fair way to properly estimate model
prediction performance is to use cross-validation as a powerful general
technique.

In summary, cross-validation combines (averages) measures of fit
(prediction error) to correct for the optimistic nature of training
error and derive a more accurate estimate of model prediction
performance.

Simply put, Cross-validation is model validation technique used to
determine how well the statistical analysis perform on an independent
dataset and is used to prevent over-fitting.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}24}]:} \PY{c}{\PYZsh{}\PYZsh{} define a scoring function to return f1 only}
         \PY{c}{\PYZsh{}\PYZsh{} if precision and recall greater than 30\PYZpc{}}
         \PY{k}{def} \PY{n+nf}{score\PYZus{}func}\PY{p}{(}\PY{n}{y\PYZus{}true}\PY{p}{,} \PY{n}{y\PYZus{}pred}\PY{p}{,} \PY{o}{*}\PY{o}{*}\PY{n}{kwargs}\PY{p}{)}\PY{p}{:}
             \PY{n}{r} \PY{o}{=} \PY{n}{recall\PYZus{}score}\PY{p}{(}\PY{n}{y\PYZus{}true}\PY{p}{,} \PY{n}{y\PYZus{}pred}\PY{p}{,} \PY{o}{*}\PY{o}{*}\PY{n}{kwargs}\PY{p}{)}
             \PY{n}{p} \PY{o}{=} \PY{n}{precision\PYZus{}score}\PY{p}{(}\PY{n}{y\PYZus{}true}\PY{p}{,} \PY{n}{y\PYZus{}pred}\PY{p}{,} \PY{o}{*}\PY{o}{*}\PY{n}{kwargs}\PY{p}{)}
             \PY{k}{if} \PY{n}{r} \PY{o}{\PYZgt{}} \PY{l+m+mf}{0.30} \PY{o+ow}{and} \PY{n}{p} \PY{o}{\PYZgt{}} \PY{l+m+mf}{0.30}\PY{p}{:}
                \PY{k}{return} \PY{n}{f1\PYZus{}score}\PY{p}{(}\PY{n}{y\PYZus{}true}\PY{p}{,} \PY{n}{y\PYZus{}pred}\PY{p}{,} \PY{o}{*}\PY{o}{*}\PY{n}{kwargs}\PY{p}{)}
             \PY{k}{else}\PY{p}{:}
                \PY{k}{return} \PY{l+m+mi}{0}
         
         \PY{n}{scorer}  \PY{o}{=} \PY{n}{make\PYZus{}scorer}\PY{p}{(}\PY{n}{score\PYZus{}func}\PY{p}{)}
\end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{n}{clf} \PY{o}{=} \PY{n}{Pipeline}\PY{p}{(}\PY{p}{[}
            \PY{c}{\PYZsh{}(\PYZsq{}scaler\PYZsq{}, StandardScaler()),}
            \PY{c}{\PYZsh{}(\PYZsq{}kbest\PYZsq{}, SelectKBest()),}
            \PY{p}{(}\PY{l+s}{\PYZsq{}}\PY{l+s}{lda}\PY{l+s}{\PYZsq{}}\PY{p}{,} \PY{n}{LDA}\PY{p}{(}\PY{p}{)}\PY{p}{)}\PY{p}{,}
            \PY{p}{(}\PY{l+s}{\PYZsq{}}\PY{l+s}{classifier}\PY{l+s}{\PYZsq{}}\PY{p}{,} \PY{n}{GaussianNB}\PY{p}{(}\PY{p}{)}\PY{p}{)}
        \PY{p}{]}\PY{p}{)}
        
        \PY{n}{parameters} \PY{o}{=} \PY{p}{\PYZob{}}
            \PY{c}{\PYZsh{}\PYZsq{}kbest\PYZus{}\PYZus{}score\PYZus{}func\PYZsq{}         : (f\PYZus{}classif, f\PYZus{}regression),}
            \PY{c}{\PYZsh{}\PYZsq{}kbest\PYZus{}\PYZus{}k\PYZsq{}                  : range(1,len(features\PYZus{}list)),}
            \PY{l+s}{\PYZsq{}}\PY{l+s}{lda\PYZus{}\PYZus{}n\PYZus{}components}\PY{l+s}{\PYZsq{}}         \PY{p}{:} \PY{n+nb}{range}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+m+mi}{40}\PY{p}{)}\PY{p}{,}
            \PY{l+s}{\PYZsq{}}\PY{l+s}{lda\PYZus{}\PYZus{}store\PYZus{}covariance}\PY{l+s}{\PYZsq{}}     \PY{p}{:} \PY{p}{(}\PY{n+nb+bp}{True}\PY{p}{,} \PY{n+nb+bp}{False}\PY{p}{)}\PY{p}{,}
            \PY{l+s}{\PYZsq{}}\PY{l+s}{lda\PYZus{}\PYZus{}solver}\PY{l+s}{\PYZsq{}}               \PY{p}{:} \PY{p}{(}\PY{l+s}{\PYZsq{}}\PY{l+s}{svd}\PY{l+s}{\PYZsq{}}\PY{p}{,}\PY{l+s}{\PYZsq{}}\PY{l+s}{eigen}\PY{l+s}{\PYZsq{}}\PY{p}{)}
        \PY{p}{\PYZcb{}}
        
        
        \PY{n}{cv} \PY{o}{=} \PY{n}{StratifiedShuffleSplit}\PY{p}{(}\PY{n}{labels}\PY{p}{,}\PY{n}{n\PYZus{}iter}\PY{o}{=}\PY{l+m+mi}{200}\PY{p}{,}\PY{n}{test\PYZus{}size}\PY{o}{=}\PY{o}{.}\PY{l+m+mi}{30}\PY{p}{)}
        \PY{n}{gs} \PY{o}{=} \PY{n}{GridSearchCV}\PY{p}{(}\PY{n}{clf}\PY{p}{,}\PY{n}{parameters}\PY{p}{,}\PY{n}{n\PYZus{}jobs}\PY{o}{=}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,}\PY{n}{cv}\PY{o}{=}\PY{n}{cv}\PY{p}{,}\PY{n}{scoring}\PY{o}{=}\PY{n}{scorer}\PY{p}{)}
        \PY{n}{gs}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{features}\PY{p}{,} \PY{n}{labels}\PY{p}{)}
        \PY{n}{clf} \PY{o}{=} \PY{n}{gs}\PY{o}{.}\PY{n}{best\PYZus{}estimator\PYZus{}}
\end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}28}]:} \PY{c}{\PYZsh{}\PYZsh{}\PYZsh{} Dump your classifier, dataset, and features\PYZus{}list so}
         \PY{c}{\PYZsh{}\PYZsh{}\PYZsh{} anyone can run/check your results.}
         
         
         \PY{n}{clf} \PY{o}{=} \PY{n}{Pipeline}\PY{p}{(}
                 \PY{n}{steps}\PY{o}{=}\PY{p}{[}
                    \PY{c}{\PYZsh{}(\PYZsq{}scaler\PYZsq{}, StandardScaler()),}
                    \PY{c}{\PYZsh{}(\PYZsq{}kbest\PYZsq{}, SelectKBest(k=5, score\PYZus{}func=f\PYZus{}classif)),}
                    \PY{p}{(}\PY{l+s}{\PYZsq{}}\PY{l+s}{lda}\PY{l+s}{\PYZsq{}}\PY{p}{,} \PY{n}{LDA}\PY{p}{(}\PY{n}{n\PYZus{}components}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{priors}\PY{o}{=}\PY{n+nb+bp}{None}\PY{p}{,} \PY{n}{shrinkage}\PY{o}{=}\PY{n+nb+bp}{None}\PY{p}{,} \PY{n}{solver}\PY{o}{=}\PY{l+s}{\PYZsq{}}\PY{l+s}{svd}\PY{l+s}{\PYZsq{}}\PY{p}{,} \PY{n}{store\PYZus{}covariance}\PY{o}{=}\PY{n+nb+bp}{False}\PY{p}{,} \PY{n}{tol}\PY{o}{=}\PY{l+m+mf}{0.0001}\PY{p}{)}\PY{p}{)}\PY{p}{,}
                    \PY{c}{\PYZsh{}(\PYZsq{}kmeans\PYZsq{}, MiniBatchKMeans(n\PYZus{}clusters=20, n\PYZus{}init=10, max\PYZus{}no\PYZus{}improvement=10, verbose=0)),}
                    \PY{p}{(}\PY{l+s}{\PYZsq{}}\PY{l+s}{classifier}\PY{l+s}{\PYZsq{}}\PY{p}{,} \PY{n}{GaussianNB}\PY{p}{(}\PY{p}{)}\PY{p}{)}
                 \PY{p}{]}
               \PY{p}{)}
         
         \PY{n}{test\PYZus{}classifier}\PY{p}{(}\PY{n}{clf}\PY{p}{,} \PY{n}{my\PYZus{}dataset}\PY{p}{,} \PY{n}{features\PYZus{}list}\PY{p}{,}\PY{n}{folds}\PY{o}{=}\PY{l+m+mi}{1000}\PY{p}{)}
         \PY{n}{dump\PYZus{}classifier\PYZus{}and\PYZus{}data}\PY{p}{(}\PY{n}{clf}\PY{p}{,} \PY{n}{my\PYZus{}dataset}\PY{p}{,} \PY{n}{features\PYZus{}list}\PY{p}{)}
\end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
Pipeline(steps=[('lda', LDA(n\_components=1, priors=None, shrinkage=None, solver='svd',
  store\_covariance=False, tol=0.0001)), ('classifier', GaussianNB())])
	Accuracy: 0.86014	Precision: 0.51656	Recall: 0.32750	F1: 0.40086	F2: 0.35337
	Total predictions: 14000	True positives:  655	False positives:  613	False negatives: 1345	True negatives: 11387
    \end{Verbatim}

    \section{Discussion and Conclusions}\label{discussion-and-conclusions}

    Recall and precision measure the quality of your result. The algorithm
results are one of the following:

classified correctly 1. true positive (TP): a POI predicted as a POI 2.
true negative (TN):a non-POI predicted as a non-POI

misclassified 1. false positive (FP): a non-POI which is predicted as a
POI 2. false negative (FN): a POI which is predicted as a non-POI

Formulas: - precision = TP/TP+FP - recall = TP/TP+FN

The precision can be interpreted as the likelihood that a person who is
identified as a POI is actually a true POI. Based on the final model,
this means 50\% POI are correctly identified and 50\% would be
incorrect. Unfortunately, the recall on this model is 31\%. This means
78\% of the time POI's would not be caught.

So, Can machine learning be used to Identify Fraud in Enron? Based on my
findings, yes. With additional time, a better understanding of the
dataset, and a few additional data points, the performance still could
be improved.

    \subsection{References}\label{references}

    https://en.wikipedia.org/wiki/Cross-validation\_(statistics)

http://www.referenceforbusiness.com/history2/57/Enron-Corporation.html

https://docs.google.com/document/d/1wCkOFWtGqOV7ira09NoZA7Otuf8SoUG2GuJUWmFbaQk/pub

http://harshtechtalk.com/model-hyperparameter-tuning-scikit-learn-using-gridsearch/

http://blog.kaggle.com/2015/07/16/scikit-learn-video-8-efficiently-searching-for-optimal-tuning-parameters/

http://scikit-learn.org/stable/modules/generated/sklearn.cross\_validation.StratifiedShuffleSplit.html

http://scikit-learn.org/stable/tutorial/machine\_learning\_map/index.html

http://stackoverflow.com/questions/332289/how-do-you-change-the-size-of-figures-drawn-with-matplotlib

https://github.com/ipython-contrib/IPython-notebook-extensions/wiki/Comment-uncomment

https://medium.com/seek-product-management/8-out-of-10-brown-cats-6e39a22b65dc

http://zacstewart.com/2014/08/05/pipelines-of-featureunions-of-pipelines.html


    % Add a bibliography block to the postdoc
    
    
    
    \end{document}
